---
title: AVL树与红黑树
date: 2018-05-14 11:17:28
tags:
- 二叉树
- 二叉查找树
- 红黑树
- AVL树
---

二叉树是一种很经典的数据结构，利用这种结构，我们可以构造出一个快速的数据查询结构，原理就是利用二叉树每个节点都有两个孩子这一性质，我们让每个树节点的左右孩子性质一样，比如左树都比父节点小，右树都比父节点大，这样的结构中我们从根查找一个数据的速度会加快很多，过程就是比当前值大就去右树找，比当前值小就去左树找。这种树我们叫做二叉排序树，它其实就是一个排序好的队列的二分查找过程的具像化结构。

这是一种很理想的数据存储结构，然而当任由数据随意顺序存储和插入的时候，有时候会出现很尴尬的结果：

举个例子：
数据插入顺序：1→2→3→4→5→6
如果对数据不进行刻意安排，那么数据最终呈现形式将是：
[![Fail Tree](/img/AVL_RBTree/FAIL_TREE.png)](/img/AVL_RBTree/FAIL_TREE.png)
是的，这是一个瘸了的二叉树，它其实就是一个简单链表，完全没有二叉树应有的样子。

AVL树和红黑树就是为了防止数据插入或删除的时候树的性能下降而产生的一种算法，或者说一种带有限制条件的二叉树结构，下面我们就来介绍一下它们。

### 树的旋转

讲AVL跟红黑树之前，我们先来复习一下大学时被我们遗忘的知识，树的旋转。

一图胜千言：
[![Tree Rote](/img/AVL_RBTree/TREE_ROTE.png)](/img/AVL_RBTree/TREE_ROTE.png)
其实这里只是写的形象一点而已，为什么把孩子拉高之后多出来的那个节点要接在以前的父节点上呢？

这里我们要理解一下树旋转本来的设计理念，树旋转最终保证的是节点的相互位置不变，比如上图中第一棵树刚开始如果使用中序遍历，得到的是：BADCE，再经过旋转之后最终的结果中序遍历结果还是BADCE，而中序遍历又是二叉排序树的排序结果遍历方法，所以这么做可以保证树的中序遍历结果不变，也就保证了二叉排序树的性质不变。


### 二叉排序树的插入和删除

在插入操作中，由于二叉排序树的性质，节点加入树中是必须遵守左小右大（或左大右小），所以二叉排序树的插入节点也需要安插在适合的位置。

但是树这种结构，如果你在半山腰插入一个元素，整个过程将影响一票节点，效率会降低很多，并且不好处理，这时候我们往往选择把节点插入在最后一层一个原本为空的位置上。

举个例子：
在下面树中插入一个新的节点4。
[![Insert Example](/img/AVL_RBTree/INSERT_EXM.png)](/img/AVL_RBTree/INSERT_EXM.png)
我们并不会在3和5之间插入节点4，具体插入过程是：
1. 从根5开始寻找，4比5小所以去左子树。
2. 新子树的根为3，4比3大所以去右子树。
3. 新子树根是空的，找到了要插入的位置，插入4。

最终插入后的效果是：
[![Insert Example](/img/AVL_RBTree/INSERT_EXM_RESULT.png)](/img/AVL_RBTree/INSERT_EXM_RESULT.png)

删除操作跟插入一样，如果半山腰删除一个元素，第一是情况复杂不好处理，修改很多指针指向性能较差，所以删除我们也需要特殊处理，将结果往底层没有子孙的节点挪。

挪的方法就是找到要删除节点左子树的最右节点，或者右子树的最左节点。

举个例子：
在下面树中删除节点5。
[![Delete Example](/img/AVL_RBTree/DELETE_EXM.png)](/img/AVL_RBTree/DELETE_EXM.png)
我们用右子树的最左节点替换，过程是：
1. 去到5的右子树。
2. 从子树根向左遍历，找到节点6，交换5和6。
3. 当前节点右子树不是空的，继续去右子树找最左节点，找到7，交换5和7。
4. 该节点没有孩子，删除节点5。

过程图：
[![Delete Example](/img/AVL_RBTree/DELETE_EXM_RESULT.png)](/img/AVL_RBTree/DELETE_EXM_RESULT.png)

下面AVL树和红黑树的插入删除也是采用这种方法处理，这样处理优势就是易于对插入和删除的情况做处理，因为都是对叶子节点的操作。

### AVL树

从难易度考虑，我们首先来说一下AVL树，AVL树得名于它的发明者G. M. Adelson-Velsky和E. M. Landis，他们在1962年的论文《An algorithm for the organization of information》中发表了它。

AVL树是一种自平衡二叉树，它的平衡原则其实很简单，左右子树深度差不超过1。为了保证AVL树的基本性质不变，每次插入或删除节点之后，如果发现树的平衡原则被打破，就要通过树的左右旋转重新调整树回到正确的平衡状态上。

所以说AVL树在存储的时候，除了基本树节点存储所需要携带的数据和左右子树的节点外，另外需要存储的是左右子树的高度（或者他们的高度差，但是高度差的维护并不比高度的维护简单），一旦发现左右子树高度差超过1就需要进行平衡调整。

所以AVL树的平衡调整分为如下几种情况：
[![AVL Remake](/img/AVL_RBTree/AVL_REMAKE.png)](/img/AVL_RBTree/AVL_REMAKE.png)
简单来说，孩子和孙子方向一致（都是左或者都是右），那么就简单一次旋转就能整理好，如果方向不一致（一左一右），先在孩子节点上把孙子节点转到同一方向上，然后再在父节点上按照刚刚方向一致的情况处理。

注意这么做之后，这棵子树的高度会发生变化，所以要在子树根（也就是刚刚的父节点）上回溯调用，在子树的父节点上重新分析，看刚刚的调整有没有在其他位置打破平衡原则，或者更新子树的父节点相关的数据。

那么一次插入/删除一共要平衡多少次呢？

这里大部分教材里面写的AVL树性能瓶颈就是每次平衡几乎都要回溯到根结点，我也基本同意这种看法。但是AVL树其实并不是每次都要回溯到根的，比如下面这个过程，注意看左右子树高度值变化：
[![AVL Demo](/img/AVL_RBTree/AVL_DEMO1.png)](/img/AVL_RBTree/AVL_DEMO1.png)

可以发现这时候，H节点的插入，除了C、D、H三个节点存在子树高度或者位置的变化，其他的节点并没有发生任何变化。所以AVL树的数据插入或删除的时间是根据树当前形态来的，不是很稳定。

### 红黑树（施工中）
